# Welcome to the OntoChoice GitHub repository
Welcome to the OntoChoice, the collaborative project for ontology selection and recommendation resources development! üöÄ

This project is **collaboratively developing a reference** for selecting terms and ontologies, encouraging systematic development and promoting reusability within the community. üåê

## What are we doing?
We are collecting a reasonably comprehensive list of metrics and indicators of the value of a term or ontology, including the following:
* organizing the metrics and indicators according to their principle function;
* characterizing the fitness for specific purposes of those metrics and indicators;
* discussion of possible sources of the needed data for those metrics;
* reflection on how the metrics can be adjusted (either in weighting, or in content) for particular use cases; and
* examples of how the metrics can be collected, presented, and discovered, now or in the future.

## Useful resources

View the [latest Evaluations for Choosing Terms and Ontologies document](https://docs.google.com/document/d/1vb-icDRYCffAn1z2jK5DmNXiYMmO9bKcri4JC9FpXuc). 

See some of our previously published documents [on our web site](https://ontochoice.github.io/choosing-terms-and-ontologies/).

Find our ongoing notes and documentation [in our Google Docs folder](https://drive.google.com/drive/folders/1Pj0R_4KA_fF2Cg_I0LazMScpkcbXK7AQ).

Most importantly, you can edit the [latest version of the document](https://docs.google.com/document/d/1vb-icDRYCffAn1z2jK5DmNXiYMmO9bKcri4JC9FpXuc). 
So that everyone gets appropriate credit, first we need to add your google account to the list of permitted editors;
contact @graybeal to be added.

## About the work

To give you an idea of our approach, the document is organized according to evaluation categories.

Below is our list of evaluation categories to date, including a partial list of the criteria in each category.
Each of these categories has multiple specific criteria that could be used to evaluate it. 
Some of the categories and criteria are fairly objective, while others are more subjective.
Similarly, some criteria can be automated, while others require human evaluation.

* **Popularity**: includes reuse, visits, selections from a search list, and other voting techniques
* **Reuse of ontologies / terms**: for both terms and ontologies, reuse must consider the reuse of the ontology as a whole, ontology fragments, design patterns, profiles, and individual terms
* **Governance**: methods and controls for modification and change tracking; trust indicators; change frequency and recency
* **Community Relevance**: ('community' typically refers to domain communities) includes adoption, standardization, and concept applicability 
* **Internationalization**: includes breadth of adoption, 'level' of governing body, amount of international re-use, and presence of multiple languages in text annotations 
* **Matching**: precision, and if evaluating multiple terms, match frequency and specialization 
* **Quality**: established by calculated metrics, or by independent assessment(s) 
* **Analytics**: includes ontology structure, ontology 'shape', and other measurable statistics
* **Best Practices Adoption**: includes documented recommendations on ontology/term creation, and FAIRness recommendations

## Contribution guidelines

Thank you for reading our guidelines!

In our community please 
* **be welcoming and patient,**
* **be considerate and respectful,** 
* **and remember to be kind and mindful of your words.**

Our work is relatively new and we do not have rigorous contribution requirements at this stage. 

We ask you to introduce yourself, attend a meeting or two, and indicate what you plan to work on
before you start making changes. We can then make arrangements to add you to our Slack, Drive, 
and GitHub community as appropriate.
